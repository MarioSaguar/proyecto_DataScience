{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebScraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep, strftime\n",
    "import random\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver de chrome \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "chrome_driver = \"chromedriver.exe\"\n",
    "driver_service = Service(executable_path = chrome_driver)\n",
    "## EL DRIVER DEBE ESTAR EN LA MISMA CARPETA QUE EL ARCHIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "navegador = webdriver.Chrome(service=driver_service) ##Abrimos el chrome del Selenium IMPORTANTE, QUITAR LOS POP UP DEL WALLAPOP AL PRINCIPIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función coge los links de aquellos anuncios de los que queremos obtener infomación.\n",
    "# Filtra por precio de coche y se va moviendo en rangos de 1000\n",
    "\n",
    "def busca_coches(precio_minimo,num_coches):\n",
    "\n",
    "    links = [] #Donde se almacenaran todos los links\n",
    "    print(\"coches de\",precio_minimo,\"a\",precio_minimo+1000) #Chivato para saber por donde vamos\n",
    "    url = \"https://es.wallapop.com/app/search?min_sale_price=\"+str(precio_minimo)+\"&max_sale_price=\"+str((precio_minimo+1000))+\"&filters_source=default_filters&category_ids=100&longitude=-3.69196&latitude=40.41956\"\n",
    "    navegador.get(url) ##Cogemos la url\n",
    "    time.sleep(3) ## Esperamos un poco a que cargue, por si acaso\n",
    "    navegador.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    boton = navegador.find_element(By.ID, \"btn-load-more\") ## El boton de cargar mas productos. AVECES DA ERROR PORQUE DI\n",
    "    boton.click() ##Pulsamos el boton AVECES DA ERROR DEJAR EL NAVEGADOR ABIERTO COMPLETAMENTE PARA QUE NO OCURRA\n",
    "    time.sleep(2) ## El boton parece que tarda bastante en cargar, por eso puse un timer de 5 segundos, seguro que se podrá bajar\n",
    "        \n",
    "    for i in range(round((num_coches)/40)): #Cada iteracion corresponde a 40 fichas de coches más, a partir de 80 interacciones ya comienza a ir lento en mi pc\n",
    "        navegador.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") ## Hacemos scroll tantas veces como digamos en el for\n",
    "        time.sleep(1)\n",
    "        print(\"Cargando\",i) ## Para saber que funciona\n",
    "            \n",
    "    navegador.page_source ## Necesitamos el soup de la página con todo el scroll\n",
    "    soup = BeautifulSoup(navegador.page_source) #Soup de la pagina cargada\n",
    "    time.sleep(2) #Que cargue todo\n",
    "    ficha = soup.find_all(\"a\", attrs = {\"class\":\"ItemCardList__item\"}) #Encuentra la ficha de todos los coches\n",
    "        \n",
    "    for i in range(len(ficha)): #Para cada ficha de coche...\n",
    "        links.append(ficha[i][\"href\"]) #Añade links a la lista\n",
    "    print(len(ficha),\"Links metidos\") #Chivato, nos dira cuantos links de coches ha introducido\n",
    "\n",
    "    #Una vez tenemos todos los links ejecutamos la funcion que recopila la informacion de cada uno de ellos\n",
    "    #data_pagina = sacar_datos(links) \n",
    "    return links #Devolverá los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función entra en cada link y extrae la información, montando un DataFrame\n",
    "\n",
    "def sacar_datos(links):\n",
    "    \n",
    "        \n",
    "    precios=[]\n",
    "    marcas=[]\n",
    "    modelos=[]\n",
    "    year=[]\n",
    "    kms=[]\n",
    "    type_vehi=[]\n",
    "    plazas=[]\n",
    "    puertas=[]\n",
    "    type_comb=[]\n",
    "    potencias=[]\n",
    "    type_cambio=[]\n",
    "    texto=[]\n",
    "    nombre_usuario=[]\n",
    "    estrellas=[]\n",
    "    resenas=[]\n",
    "    ubicacion=[]\n",
    "    num_ventas=[]\n",
    "    \n",
    "    for j in links:\n",
    "        print(j)\n",
    "        navegador.get(j)\n",
    "        time.sleep(1)\n",
    "        navegador.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.5)\n",
    "        soup = BeautifulSoup(navegador.page_source)\n",
    "        error = soup.find('div', attrs = {'class': 'not-found-page_Error__container__GtFkg d-flex flex-column align-items-center'}) #Para cuando la pagina no exista\n",
    "        error2 = soup.find('div', attrs = {'class': 'error-page_Error__container__qaYIn d-flex flex-column align-items-center'}) ## Para cuando la pagina de error\n",
    "        if error != None: ## Si la pagina no existe el contenido del error no estará vacio\n",
    "            continue ## Pasaremos a la siguiente iteracion, ya que en la página vacia no hay datos que poner       \n",
    "        if error2 != None: ## Para otro problema en la pagina\n",
    "            continue\n",
    "\n",
    "            \n",
    "        precio=soup.find('div', attrs={'aria-label':'Item Price'})\n",
    "        if len(precio)==1:\n",
    "            precios.append(precio.span.text.split()[0])\n",
    "        elif len(precio)==2:\n",
    "            p=precio.find('span', attrs={'class':'item-detail-price_ItemDetailPrice--standardFinanced__14D3z'})\n",
    "            precios.append(p.text.split()[0])\n",
    "\n",
    "        else:\n",
    "            precios.append(np.NaN)\n",
    "      \n",
    "\n",
    "    # Vamos a sacar el nombre de usuario\n",
    "        nombre = soup.find_all('h3')\n",
    "        \n",
    "        # nombre = soup.find('h3', attrs={'class':'text-truncate mb-0 item-detail-header_ItemDetailHeader__text--typoMidM__VeCLc'})\n",
    "        if nombre is not None:\n",
    "            nombre_usuario.append(nombre[0].text)\n",
    "        else:\n",
    "            nombre_usuario.append(np.NaN)\n",
    "\n",
    "    # Vamos a sacar la lista de comentarios. El if/else es para cuando alguno nos de un problema.\n",
    "        textos = soup.find(\"section\", attrs = {\"class\":\"item-detail_ItemDetail__description__7rXXT py-4\"})\n",
    "        if textos is not None:\n",
    "            texto.append(textos.text)\n",
    "        else:\n",
    "            texto.append(np.NaN)\n",
    "\n",
    "        # precio=soup.find('div', attrs={'aria-label':'Item Price'})\n",
    "        # precios.append(precio.span.text.split()[0])\n",
    "        # marc_mod=soup.find_all('span', attrs={'class':\"item-detail-seo-bubble_ItemDetailSEOBubble__link__yZP8O px-3 py-2 text-truncate align-middle\"})\n",
    "        # marcas.append(marc_mod[0].text)\n",
    "        # modelo.append(marc_mod[1].text)\n",
    "\n",
    "    # Estrellas\n",
    "        stars = soup.find(\"span\", attrs = {\"class\":\"item-detail-header_ItemDetailHeader__text--typoLowS__9JNQi ml-1\"})\n",
    "        if stars != None:\n",
    "            estrellas.append(stars.text)\n",
    "        else:\n",
    "            estrellas.append(np.NaN)\n",
    "\n",
    "    # Reseñas \n",
    "        num_resenas = soup.find(\"span\", attrs = {\"class\":\"item-detail-header_ItemDetailHeader__text--typoLowSContentLow__UyhmS ml-1\"})\n",
    "        if num_resenas != None:\n",
    "            resenas.append(num_resenas.text[1])\n",
    "        else:\n",
    "            resenas.append(np.NaN)\n",
    "    # Nº de ventas\n",
    "        num_venta = soup.find('span', attrs = {'class': 'item-detail-header_ItemDetailHeader__text--typoLowS__9JNQi mr-1'})\n",
    "        if num_venta != None:\n",
    "            num_ventas.append(num_venta.text.split()[0])\n",
    "        else:\n",
    "            num_ventas.append(np.NaN)\n",
    "    # Ubicación\n",
    "        ubicaciones = soup.find(\"a\", attrs = {\"class\":\"item-detail-location_ItemDetailLocation__link__s4oPx\"})\n",
    "        if ubicaciones == None: ## Excepcion, a veces da error\n",
    "            ubicaciones = soup.find(\"div\", attrs = {\"class\":\"d-flex item-detail-location_ItemDetailLocation___QiCU\"})\n",
    "            if ubicaciones == None: ##En casa de que tampoco hubiera ubicacion\n",
    "                continue ##Pase al siguiente\n",
    "        ubicacion.append(ubicaciones.text)\n",
    "    # Vamos a sacar la lista de características (tipo, nº de plazas, nº de puertas, , tipo de combustible, potencia en CV, tipo de cambio).\n",
    "    # El if/else es para cuando alguno nos de un problema.\n",
    "        carac=soup.find_all('span', attrs={'class':\"item-detail-attributes-info_AttributesInfo__measure__uZS62 mt-1\"})\n",
    "        if len(carac)==6:\n",
    "            type_vehi.append(carac[0].text)\n",
    "            plazas.append(carac[1].text.split()[0])\n",
    "            puertas.append(carac[2].text.split()[0])\n",
    "            type_comb.append(carac[3].text)\n",
    "            potencias.append(carac[4].text.split()[0])\n",
    "            type_cambio.append(carac[5].text)\n",
    "        else:\n",
    "            type_vehi.append(np.NaN)\n",
    "            plazas.append(np.NaN)\n",
    "            puertas.append(np.NaN)\n",
    "            type_comb.append(np.NaN)\n",
    "            potencias.append(np.NaN)\n",
    "            type_cambio.append(np.NaN)\n",
    "\n",
    "\n",
    "    # Vamos a sacar la lista de varios (marca, modelo, año y kilómetros).\n",
    "    # El if/else es para cuando alguno nos de un problema.\n",
    "        varios=soup.find_all('div',attrs={'class':\"item-detail-car-extra-info_ItemDetailCarExtraInfo__section__n4g_P d-flex align-items-center\"})\n",
    "        if len(varios)==4:\n",
    "            marcas.append(varios[0].find_all('span')[1].text)\n",
    "            modelos.append(varios[1].find_all('span')[1].text)\n",
    "            year.append(varios[2].find_all('span')[1].text)\n",
    "            kms.append(varios[3].find_all('span')[1].text)\n",
    "\n",
    "        else:\n",
    "            marcas.append(np.NaN)\n",
    "            modelos.append(np.NaN)\n",
    "            year.append(np.NaN)\n",
    "            kms.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion del dataframe donde meteremos todos los datos. Recordar  vaciarlo \n",
    "data_total = pd.DataFrame([], columns=['Marca', 'Modelo', 'Año', 'Potencia', 'Plazas', 'Nº de puertas',\n",
    "         'km', 'Tipo de vehiculo', 'Combustible', 'Cambio', 'Comentarios','Nombre usuario',\n",
    "          'Puntuacion', 'Nº valoraciones', 'Nº Ventas', 'Ubicacion', 'Precio' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metemos coches de 8000\n",
      "coches de 8000 a 9000\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.72)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6AFFBEEA2+31554]\n\t(No symbol) [0x00007FF6AFF37ED9]\n\t(No symbol) [0x00007FF6AFDF872A]\n\t(No symbol) [0x00007FF6AFDCD995]\n\t(No symbol) [0x00007FF6AFE744D7]\n\t(No symbol) [0x00007FF6AFE8C051]\n\t(No symbol) [0x00007FF6AFE6CDD3]\n\t(No symbol) [0x00007FF6AFE3A33B]\n\t(No symbol) [0x00007FF6AFE3AED1]\n\tGetHandleVerifier [0x00007FF6B02C8B1D+3217341]\n\tGetHandleVerifier [0x00007FF6B0315AE3+3532675]\n\tGetHandleVerifier [0x00007FF6B030B0E0+3489152]\n\tGetHandleVerifier [0x00007FF6B006E776+750614]\n\t(No symbol) [0x00007FF6AFF4375F]\n\t(No symbol) [0x00007FF6AFF3EB14]\n\t(No symbol) [0x00007FF6AFF3ECA2]\n\t(No symbol) [0x00007FF6AFF2E16F]\n\tBaseThreadInitThunk [0x00007FFA324F7374+20]\n\tRtlUserThreadStart [0x00007FFA333DCC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(links) \u001b[38;5;241m<\u001b[39m (num_coches\u001b[38;5;241m-\u001b[39m(num_coches\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)): \u001b[38;5;66;03m##Para cuando nos coge menos de 3000 links. Le dejo un margen de un 10% 3000 = 2700 - 3000        \u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetemos coches de\u001b[39m\u001b[38;5;124m\"\u001b[39m,precio_minimo)\n\u001b[1;32m---> 14\u001b[0m     links \u001b[38;5;241m=\u001b[39m busca_coches(precio_minimo,num_coches) \u001b[38;5;66;03m## Sacame los datos de la pagina con el filtro aplicado, entre el rango de precios indicado arriba\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     contador\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#Para romper el bucle en caso de que no encontrara el número de links que queremos. Le damos 3 intentos para buscarlo\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m contador \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mbusca_coches\u001b[1;34m(precio_minimo, num_coches)\u001b[0m\n\u001b[0;32m      9\u001b[0m navegador\u001b[38;5;241m.\u001b[39mget(url) \u001b[38;5;66;03m##Cogemos la url\u001b[39;00m\n\u001b[0;32m     10\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m## Esperamos un poco a que cargue, por si acaso\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m navegador\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     13\u001b[0m boton \u001b[38;5;241m=\u001b[39m navegador\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mID, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbtn-load-more\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m## El boton de cargar mas productos. AVECES DA ERROR PORQUE DI\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JSaguar\\Desktop\\Visual Studio Code\\Folder\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:414\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    411\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    412\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(command, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m\"\u001b[39m: script, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: converted_args})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\JSaguar\\Desktop\\Visual Studio Code\\Folder\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\JSaguar\\Desktop\\Visual Studio Code\\Folder\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.72)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6AFFBEEA2+31554]\n\t(No symbol) [0x00007FF6AFF37ED9]\n\t(No symbol) [0x00007FF6AFDF872A]\n\t(No symbol) [0x00007FF6AFDCD995]\n\t(No symbol) [0x00007FF6AFE744D7]\n\t(No symbol) [0x00007FF6AFE8C051]\n\t(No symbol) [0x00007FF6AFE6CDD3]\n\t(No symbol) [0x00007FF6AFE3A33B]\n\t(No symbol) [0x00007FF6AFE3AED1]\n\tGetHandleVerifier [0x00007FF6B02C8B1D+3217341]\n\tGetHandleVerifier [0x00007FF6B0315AE3+3532675]\n\tGetHandleVerifier [0x00007FF6B030B0E0+3489152]\n\tGetHandleVerifier [0x00007FF6B006E776+750614]\n\t(No symbol) [0x00007FF6AFF4375F]\n\t(No symbol) [0x00007FF6AFF3EB14]\n\t(No symbol) [0x00007FF6AFF3ECA2]\n\t(No symbol) [0x00007FF6AFF2E16F]\n\tBaseThreadInitThunk [0x00007FFA324F7374+20]\n\tRtlUserThreadStart [0x00007FFA333DCC91+33]\n"
     ]
    }
   ],
   "source": [
    "#Cada iteración irá del precio minimo al precio minimo +1000, para abarcar el máximo número de coches posibles\n",
    "# A partir de 4000 coches en num_coches el rendimiento del navegador empieza a ir lento (al menos el mio)\n",
    "precio_minimo = 8000 ##Empezamos a buscar coches a partir del rango mínimo de precio (1000) no he puesto 0 porque salen ventas raras\n",
    "precio_maximo = 10000 ##Precio máximo hasta donde queremos buscar. NO PUEDE SER IGUAL AL PRECIO MINIMO\n",
    "num_coches = 3000 # Numero de coches que queremos coger por cada rango de precio. Es una medida APROXIMADA, siempre suele coger 100+ de lo indicado, irrelevante, queremos MUCHOS datos\n",
    "links = [] ## Para la condicion del while\n",
    "inicio = 0 ## Por que numero de link empezara a sacar datos. Por defecto el 0. \n",
    "\n",
    "for j in range((precio_maximo-precio_minimo)//1000):\n",
    "    links = []\n",
    "    contador = 0 ##Para que no se quede en bucle infinito si no encontrara los links, podría darse el caso de que no hubiera tal cantidad de links\n",
    "    while len(links) < (num_coches-(num_coches/10)): ##Para cuando nos coge menos de 3000 links. Le dejo un margen de un 10% 3000 = 2700 - 3000        \n",
    "        print(\"metemos coches de\",precio_minimo)\n",
    "        links = busca_coches(precio_minimo,num_coches) ## Sacame los datos de la pagina con el filtro aplicado, entre el rango de precios indicado arriba\n",
    "        contador+=1 #Para romper el bucle en caso de que no encontrara el número de links que queremos. Le damos 3 intentos para buscarlo\n",
    "        if contador > 3:\n",
    "            break\n",
    "\n",
    "    for j in range(inicio,len(links)+1):\n",
    "        print(\"Link nº\",j) #Así veriamos donde se ha dado el error\n",
    "        dato_link = sacar_datos(links[j-1:j]) ## Que llame a la funcion tantas veces como numero de links tengamos\n",
    "        data_total = pd.concat([data_total, dato_link], ignore_index=True) # No se como añadir el dataframe de dato_link sin concatenarlo\n",
    "    \n",
    "    data_total.to_csv(str(precio_minimo)+\"CochesWallapop_Mario.csv\",index = False)\n",
    "    print(\"datos entre\",str(precio_minimo),\"y\",str(precio_minimo+1000),\"introducidos\")\n",
    "    precio_minimo+=1000 ## Pasamos al siguiente rango\n",
    "    print(precio_minimo, \"que pasaaaaaa que no suma\")\n",
    "    time.sleep(60) #Vamos a descansar\n",
    "    \n",
    "    data_total = pd.DataFrame([], columns=['Marca', 'Modelo', 'Año', 'Potencia', 'Plazas', 'Nº de puertas',\n",
    "         'km', 'Tipo de vehiculo', 'Combustible', 'Cambio', 'Comentarios','Nombre usuario',\n",
    "          'Puntuacion', 'Nº valoraciones', 'Nº Ventas', 'Ubicacion', 'Precio' ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si buscas varios rangos de 1000 (ej. de 5000 a 10000) y da algún fallo o quieres interrumpirlo manualmente,\n",
    "# puedes guardar a mano los datos que tengas en un csv, siempre que haya completado algún rango de 1000\n",
    "# ejemplo: busco de 5000 a 10000 y cuando está buscando de 7000 a 8000 da fallo, o interrumpo manualmente; podría guardar a mano los\n",
    "# rangos de 5000 a 6000 y de 6000 a 7000\n",
    "data_total.to_csv('Wallapop_9-10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez tengamos el archivo .csv con los datos sucios, hay que limpiarlos con las funciones 'limpieza_datos' y 'agrupa marcas'\n",
    "# Importante cargar el .csv de la forma adecuada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta es la función general de limpieza: cambia caracteres y sirve de filtro. \n",
    "# Para que funcione correctamente, el archivo .csv obtenido del web scrapping debe cargarse de la siguiente manera:\n",
    "# data1 = pd.read_csv('Wallapop_varios.csv', dtype={'Marca': 'object', 'Modelo': 'object', 'Año': 'float64', 'Potencia': 'object',\n",
    "#                                              'Plazas': 'float64', 'Nº de puertas': 'float64', 'km': 'float64', 'Tipo de vehiculo': 'object',\n",
    "#                                              'Combustible': 'object', 'Cambio': 'object', 'Comentarios': 'object', 'Nombre usuario': 'object',\n",
    "#                                              'Puntuacion': 'float64', 'Nº valoraciones': 'float64', 'Nº ventas': 'float64', \n",
    "#                                              'Ubicacion': 'object', 'Precio': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_datos(df):\n",
    "\n",
    "## Quitamos nulos y duplicados\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    ## Procedemos con las variables:\n",
    "    \n",
    "    #Año\n",
    "    df = df[df[\"Año\"] >=1900] ## Quitamos todos los coches con año inferior a 1900\n",
    "    df[\"Año\"] = df[\"Año\"].astype(\"int\") ## Pasamos todo a int\n",
    "    \n",
    "    #Potencia   \n",
    "    df.loc[df['Potencia'].str.len()>5, 'Potencia'] = \"10000\" ##Para cuando el string sea mayor a 5, que serán potencias con errores como \"caballos\" o 1,324,54    \n",
    "    df['Potencia'] = df['Potencia'].str.replace(',', '', regex=False) # Si hay comas que las quite, que luego da problemas\n",
    "    df['Potencia'] = df[\"Potencia\"].astype(float)\n",
    "    df['Potencia'] = round(df[\"Potencia\"])\n",
    "    df['Potencia'] = df[\"Potencia\"].astype(int)\n",
    "    df = df[(df[\"Potencia\"] <=500) & (df[\"Potencia\"] >=40)] ##Quitamos coches con potencia superior a 500\n",
    "\n",
    "    #Puertas\n",
    "    df[\"Nº de puertas\"] = df[\"Nº de puertas\"].astype(\"float\")\n",
    "    df['Nº de puertas'] = round(df[\"Nº de puertas\"])\n",
    "    df[\"Nº de puertas\"] = df[\"Nº de puertas\"].astype(\"int\") ## Pasamos todo a int\n",
    "    df = df[(df['Nº de puertas'] >= 2) & (df['Nº de puertas'] <= 10)] ##Quitamos menor a 2 puertas y superiores a 10\n",
    "    \n",
    "    #Kilometros\n",
    "    df[\"km\"] = df[\"km\"].astype(\"int\") #Pasamos a int\n",
    "    df = df[df[\"km\"] <=1000000] ##Coches con mas de 1m de km fuera\n",
    "    \n",
    "    #Plazas\n",
    "    df[\"Plazas\"] = df[\"Plazas\"].astype(\"float\")\n",
    "    df['Plazas'] = round(df[\"Plazas\"])\n",
    "    df[\"Plazas\"] = df[\"Plazas\"].astype(\"int\") ##Pasamos a int\n",
    "    df = df[(df['Plazas'] >= 2) & (df['Plazas'] <= 10)] ##Quitamos menor a 2 plazas y superiores a 10\n",
    "    \n",
    "    #Puntuaciones y ventas las pasamos a int\n",
    "    df[\"Puntuacion\"] = df[\"Puntuacion\"].astype(\"float\")\n",
    "    df['Puntuacion'] = round(df[\"Puntuacion\"])\n",
    "    df[\"Puntuacion\"] = df[\"Puntuacion\"].astype(\"int\") ## Pasamos todo a int\n",
    "    df[\"Nº Ventas\"] = df[\"Nº Ventas\"].astype(\"int\") ## Pasamos todo a int\n",
    "    \n",
    "    #Eliminamos nº de valoraciones ya que no pudieron obtenerse correctamente\n",
    "    df = df.drop(columns=['Nº valoraciones'])\n",
    "    \n",
    "    #Transformaciones a la variable objetivo para pasar de string a int\n",
    "    df['Precio'] = df['Precio'].str.replace('.', '', regex=False) ##Quitamos puntos que molesten\n",
    "    df['Precio'] = df['Precio'].str.replace(',', '.', regex=False) # Cambiamos , por . para que pueda pasarlo a float\n",
    "    df['Precio']=df['Precio'].astype('float') ##Pasamos a float para las comas. Si pasamos directamente a int da error\n",
    "    df['Precio']=df['Precio'].astype('int') ##De float lo pasamos a int\n",
    "\n",
    "    df = df.drop_duplicates(subset=['Marca','Modelo','Año','Potencia','Plazas','Nº de puertas',\n",
    "                                'km','Tipo de vehiculo','Combustible','Cambio','Precio'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función sirve para agrupar las marcas, independientemente de errores ortográficos o distición entre mayúsculas y minúsculas\n",
    "\n",
    "def agrupa_marcas(data):\n",
    "    from unidecode import unidecode\n",
    "    data[\"Marca\"] = data[\"Marca\"].str.upper() ## Primero pasamos todo a mayusculas, ya con esto homogeneizamos columnas\n",
    "    data[\"Marca\"] = data[\"Marca\"].apply(unidecode) ## Quitamos todos los acentos. Recordar importar el unidecode from unidecode import unidecode\n",
    "    marcas = data[\"Marca\"].value_counts().index # Metemos todas las marcas de coches que tenemos\n",
    "\n",
    "    for i in marcas: ##Ahora para cada marca, empezando desde la primera\n",
    "        contiene_marca = data[\"Marca\"].str.contains(i, case=False, na=False) \n",
    "        data.loc[contiene_marca, \"Marca\"] = i ##Sustituimos la columna que contiene esa marca con la marca inicial\n",
    "\n",
    "    #Una vez agrupadas las marcas eliminamos aquellas únicas que tengan pocos valores\n",
    "    marcas_eliminar = []\n",
    "    filtro = data[\"Marca\"].value_counts() <= 5 #Metemos en el filtro todas las marcas y si tienen menos de 5 filas será true\n",
    "\n",
    "    for i in range(len(filtro)):\n",
    "        if filtro.values[i] == True: ##\n",
    "            marcas_eliminar.append(filtro.index[i])\n",
    "\n",
    "    data = data[~data[\"Marca\"].isin(marcas_eliminar)] ## Eliminamos todas las filas donde esten las marcas a eliminar, la virgulilla dice que haga lo contrario\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
